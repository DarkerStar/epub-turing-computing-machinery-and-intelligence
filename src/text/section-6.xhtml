<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en" xml:lang="en">
<head>
	<meta charset="utf-8"/>
	
	<title>6. Contrary Views on the Main Question • Computing Machinery and Intelligence</title>
	
	<link rel="stylesheet" href="../style/style.css"/>
</head>
<body epub:type="bodymatter">
<section id="section-6" epub:type="chapter">
<h1 id="contrary-views-on-the-main-question"><span class="section-number">6.</span> Contrary Views on the Main Question</h1>

<p>
	We may now consider the ground to have been cleared and we are ready to proceed to the debate on our question, “Can machines think?” and the variant of it quoted at the end of the last section.
	We cannot altogether abandon the original form of the problem, for opinions will differ as to the appropriateness of the substitu&#173;tion and we must at least listen to what has to be said in this connection.
</p>
<p>
	It will simplify matters for the reader if I explain first my own beliefs in the matter.
	Consider first the more accurate form of the question.
	I believe that in about fifty years’ time it will be possible, to programme computers, with a storage capacity of about 10<sup>9</sup>, to make them play the imitation game so well that an average interrogator will not have more than 70 per cent. chance of making the right identification after five minutes of questioning.
	The original question, “Can machines think?” I believe to be too meaningless to deserve discussion.
	Nevertheless I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.
	I believe further that no useful purpose is served by concealing these beliefs.
	The popular view that scientists proceed inexorably from well-established fact to well-established fact, never being influenced by any improved conjecture, is quite mistaken.
	Provided it is made clear which are proved facts and which are conjectures, no harm can result.
	Conjectures are of great importance since they suggest useful lines of research.
</p>
<p>
	<span epub:type="pagebreak" id="page-443" title="443"></span>
	I now proceed to consider opinions opposed to my own.
</p>
<section id="subsection-6-1" epub:type="subchapter">
<h1 id="the-theological-objection">The Theological Objection</h1>
<p>
	Thinking is a function of man’s immortal soul.
	God has given an immortal soul to every man and woman, but not to any other animal or to machines.
	Hence no animal or machine can think.
</p>
<p>
	I am unable to accept any part of this, but will attempt to reply in theological terms.
	I should find the argument more convincing if animals were classed with men, for there is a greater difference, to my mind, between the typical animate and the inanimate than there is between man and the other animals.
	The arbitrary character of the orthodox view becomes clearer if we consider how it might appear to a member of some other religious community.
	How do Christians regard the Moslem view that women have no souls?
	But let us leave this point aside and return to the main argument.
	It appears to me that the argument quoted above implies a serious restriction of the omni&#173;potence of the Almighty.
	It is admitted that there are certain things that He cannot do such as making one equal to two,<sup><a id="fn1-src" epub:type="noteref" href="#fn1" class="footnote-ref">1</a></sup> but should we not believe that He has freedom to confer a soul on an elephant if He sees fit?
	We might expect that He would only exercise this power in conjunction with a mutation which provided the elephant with an appropriately improved brain to minister to the needs of this soul.
	An argument of exactly similar form may be made for the case of machines.
	It may seem different because it is more difficult to “swallow”.
	But this really only means that we think it would be less likely that He would con&#173;sider the circumstances suitable for conferring a soul.
	The cir&#173;cumstances in question are discussed in the rest of this paper.
	In attempting to construct such machines we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates.
</p>
<aside id="fn1" epub:type="footnote" class="footnote">
	<sup><a class="footnote-return" href="#fn1-src">1</a></sup>
	Possibly this view is heretical. St. Thomas Aquinas (<i lang="la" xml:lang="la">Summa Theologica</i>, quoted by Bertrand Russell <abbr title="page">p.</abbr> 480) states that God cannot make a man to have no soul.
	But this may not be a real restriction on His powers, but only a result of the fact that men’s souls are immortal, and therefore indestructible.
</aside>
<p>
	However, this is mere speculation.
	I am not very impressed with theological arguments whatever they may be used to support.
	Such arguments have often been found unsatisfactory in the past.
	In the time of Galileo it was argued that the texts, <q>And the sun stood still… and hasted not to go down about a whole day</q> (Joshua <span class="nobr">ⅹ. 13</span>) and <q>He laid the foundations of the earth,<span epub:type="pagebreak" id="page-444" title="444"></span> that it should not move at any time</q> (Psalm <span class="nobr">ⅽⅴ. 5</span>) were an adequate refutation of the Copernican theory.
	With our present knowledge such an argument appears futile.
	When that know&#173;ledge was not available it made a quite different impression.
</p>
</section>
<section id="subsection-6-2" epub:type="subchapter">
<h1 id="the-heads-in-the-sand-objection">The ‘Heads in the Sand’ Objection</h1>
<p>
	“The consequences of machines thinking would be too dreadful.
	Let us hope and believe that they cannot do so.”
</p>
<p>
	This argument is seldom expressed quite so openly as in the form above.
	But it affects most of us who think about it at all.
	We like to believe that Man is in some subtle way superior to the rest of creation.
	It is best if he can be shown to be <em>necessarily</em> superior, for then there is no danger of him losing his commanding position.
	The popularity of the theological argument is clearly connected with this feeling.
	It is likely to be quite strong in in&#173;tellectual people, since they value the power of thinking more highly than others, and are more inclined to base their belief in the superiority of Man on this power.
</p>
<p>
	I do not think that this argument is sufficiently substantial to require refutation.
	Consolation would be more appropriate: perhaps this should be sought in the transmigration of souls.
</p>
</section>
<section id="subsection-6-3" epub:type="subchapter">
<h1 id="the-mathematical-objection">The Mathematical Objection</h1>
<p>
	There are a number of results of mathematical logic which can be used to show that there are limitations to the powers of discrete-state machines.
	The best known of these results is known as Gödel’s theorem,<sup><a id="fn2-src" epub:type="noteref" href="#fn2" class="footnote-ref">2</a></sup> and shows that in any sufficiently powerful logical system statements can be formulated which can neither be proved nor disproved within the system, unless possibly the system itself is inconsistent.
	There are other, in some respects similar, results due to <cite>Church</cite>, <cite>Kleene</cite>, <cite>Rosser</cite>, and <cite>Turing</cite>.
	The latter result is the most con&#173;venient to consider, since it refers directly to machines, whereas the others can only be used in a comparatively indirect argument: for instance if Gödel’s theorem is to be used we need in addition to have some means of describing logical systems in terms of machines, and machines in terms of logical systems.
	The result in question refers to a type of machine which is essentially a digital computer with an infinite capacity.
	It states that there are certain things that such a machine cannot do.
	If it is rigged up to give answers to questions as in the imitation game, there will be some questions to which it will either give a wrong answer, or fail to give an answer at all however much time is allowed for a reply.
	There may, of course, be many such questions, and questions which cannot be answered by one machine may be satisfactorily<span epub:type="pagebreak" id="page-445" title="445"></span> answered by another.
	We are of course supposing for the present that the questions are of the kind to which an answer “Yes” or “No” is appropriate, rather than questions such as “What do you think of Picasso?”
	The questions that we know the machines must fail on are of this type, “Consider the machine specified as follows.
	…
	Will this machine ever answer ‘Yes’ to any question?”
	The dots are to be replaced by a des&#173;cription of some machine in a standard form, which could be something like that used in <a href="section-5.xhtml">§5</a>.
	When the machine described bears a certain comparatively simple relation to the machine which is under interrogation, it can be shown that the answer is either wrong or not forthcoming.
	This is the mathematical result: it is argued that it proves a disability of machines to which the human intellect is not subject.
</p>
<aside id="fn2" epub:type="footnote" class="footnote">
	<sup><a class="footnote-return" href="#fn2-src">2</a></sup>
	Author’s names in italics refer to the Bibliography.
</aside>
<p>
	The short answer to this argument is that although it is established that there are limitations to the powers of any particular machine, it has only been stated, without any sort of proof, that no such limitations apply to the human intellect.
	But I do not think this view can be dismissed quite so lightly.
	Whenever one of these machines is asked the appropriate critical question, and gives a definite answer, we know that this answer must be wrong, and this gives us a certain feeling of superiority.
	Is this feeling illusory?
	It is no doubt quite genuine, but I do not think too much importance should be attached to it.
	We too often give wrong answers to questions ourselves to be justified in being very pleased at such evidence of fallibility on the part of the machines.
	Further, our superiority can only be felt on such an occasion in relation to the one machine over which we have scored our petty triumph.
	There would be no question of triumphing simultaneously over <em>all</em> machines.
	In short, then, there might be men cleverer than any given machine, but then again there might be other machines cleverer again, and so on.
</p>
<p>
	Those who hold to the mathematical argument would, I think, mostly he willing to accept the imitation game as a basis for discussion.
	Those who believe in the two previous objections would probably not be interested in any criteria.
</p>
</section>
<section id="subsection-6-4" epub:type="subchapter">
<h1 id="the-argument-from-consciousness">The Argument from Consciousness</h1>
<p>
	This argument is very, well expressed in <cite>Professor Jefferson’s</cite> Lister Oration for 1949, from which I quote.
	“Not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain—that is, not only write it but know that it had written it.
	No mechanism could feel (and not merely<span epub:type="pagebreak" id="page-446" title="446"></span> artificially signal, an easy contrivance) pleasure at its successes, grief when its valves fuse, be warmed by flattery, be made miserable by its mistakes, be charmed by sex, be angry or de&#173;pressed when it cannot get what it wants.”
</p>
<p>
	This argument appears to be a denial of the validity of our test.
	According to the most extreme form of this view the only way by which one could be sure that machine thinks is to <em>be</em> the machine and to feel oneself thinking.
	One could then des&#173;cribe these feelings to the world, but of course no one would be justified in taking any notice.
	Likewise according to this view the only way to know that a <em>man</em> thinks is to be that particular man.
	It is in fact the solipsist point of view.
	It may be the most logical view to hold but it makes communication of ideas difficult.
	<var>A</var> is liable to believe “<var>A</var> thinks but <var>B</var> does not” whilst <var>B</var> believes “<var>B</var> thinks but <var>A</var> does not”.
	Instead of arguing continually over this point it is usual to have the polite con&#173;vention that everyone thinks.
</p>
<p>
	I am sure that Professor Jefferson does not wish to adopt the extreme and solipsist point of view.
	Probably he would be quite willing to accept the imitation game as a test.
	The game (with the player <var>B</var> omitted) is frequently used in practice under the name of <i lang="la" xml:lang="la">viva voce</i> to discover whether some one really understands something or has ‘learnt it parrot fashion’. Let us listen in to a part of such a <i lang="la" xml:lang="la">viva voce</i>:
</p>
<dl class="conversation no-indent">
	<dt><span class="speaker">Interrogator :</span></dt>
	<dd>
		In the first line of your sonnet which reads “Shall I compare thee to a summer’s day”, would not “a spring day” do as well or better?
	</dd>
	<dt><span class="speaker">Witness :</span></dt>
	<dd>
		It wouldn’t scan.
	</dd>
	<dt><span class="speaker">Interrogator :</span></dt>
	<dd>
		How about “a winter’s day”
		That would scan all right.
	</dd>
	<dt><span class="speaker">Witness :</span></dt>
	<dd>
		Yes, but nobody wants to be compared to a winter’s day.
	</dd>
	<dt><span class="speaker">Interrogator :</span></dt>
	<dd>
		Would you say Mr. Pickwick reminded you of Christmas?
	</dd>
	<dt><span class="speaker">Witness :</span></dt>
	<dd>
		In a way.
	</dd>
	<dt><span class="speaker">Interrogator :</span></dt>
	<dd>
		Yet Christmas is a winter’s day, and I do not think Mr. Pickwick would mind the comparison.
	</dd>
	<dt><span class="speaker">Witness :</span></dt>
	<dd>
		I don’t think you’re serious.
		By a winter’s day one means a typical winter’s day, rather than a special one like Christmas.
	</dd>
</dl>
<p>
	And so on, What would Professor Jefferson say if the sonnet-writing machine was able to answer like this in the <i lang="la" xml:lang="la">viva voce</i>?
	I do not know whether he would regard the machine as “merely<span epub:type="pagebreak" id="page-447" title="447"></span> artificially signalling” these answers, but if the answers were as satisfactory and sustained as in the above passage I do not think he would describe it as “an easy contrivance”.
	This phrase is, I think, intended to cover such devices as the inclusion in the machine of a record of someone reading a sonnet, with appropriate switching to turn it on from time to time.
</p>
<p>
	In short then, I think that most of those who support the argument from consciousness could be persuaded to abandon it rather than be forced into the solipsist position.
	They will then probably be willing to accept our test.
</p>
<p>
	I do not wish to give the impression that I think there is no mystery about consciousness.
	There is, for instance, something of a paradox connected with any attempt to localise it.
	But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper.
</p>
</section>
<section id="subsection-6-5" epub:type="subchapter">
<h1 id="arguments-from-various-disabilities">Arguments from Various Disabilities</h1>
<p>
	These arguments take the form, “I grant you that you can make machines do all the things you have mentioned but you will never be able to make one to do <var>X</var>.”
	Numerous features <var>X</var> are suggested in this connection.
	I offer a selection:
</p>
<p class="separated">
	Be kind, resourceful, beautiful, friendly (<a href="#page-448" class="page-link"><abbr title="page">p.</abbr> 448</a>), have initiative, have a sense of humour, tell right from wrong, make mistakes (<a href="#page-448" class="page-link"><abbr title="page">p.</abbr> 448</a>), fall in love, enjoy strawberries and cream (<a href="#page-448" class="page-link"><abbr title="page">p.</abbr> 448</a>), make some one fall in love with it, learn from experience (<a href="section-7.xhtml#page-456" class="page-link"><abbr title="pages">pp.</abbr> 456 <abbr title="and the following">f.</abbr></a>), use words properly, be the subject of its own thought (<a href="#page-449" class="page-link"><abbr title="page">p.</abbr> 449</a>), have as much diversity of behaviour as a man, do something really new (<a href="#page-450" class="page-link"><abbr title="page">p.</abbr> 450</a>).
	(Some of these disabilities are given special consideration as indicated by the page numbers.)
</p>
<p class="no-indent">
	No support is usually offered for these statements.
	I believe they are mostly founded on the principle of scientific induction.
	A man has seen thousands of machines in his lifetime.
	From what he sees of them he draws a number of general conclusions.
	They are ugly, each is designed for a very limited purpose, when required for a minutely different purpose they are useless, the variety of behaviour of any one of them is very small, <abbr title="and so on">etc.</abbr>, <abbr title="and so on">etc.</abbr>
	Naturally he concludes that these are necessary properties of machines in general.
	Many of these limitations are associated with the very small storage capacity of most machines.
	(I am assuming that the idea of storage capacity is extended in some way to cover machines other than discrete-state machines.
	<span epub:type="pagebreak" id="page-448" title="448"></span>
	The exact definition does not matter as no mathematical accuracy is claimed in the present discussion.)
	A few years ago, when very little had been heard of digital computers, it was possible to elicit much incredulity concerning them, if one mentioned their properties without describing their construction.
	That was presumably due to a similar application of the principle of scientific induction.
	These applications of the principle are of course largely unconscious.
	When a burnt child fears the fire and shows that he fears it by avoiding it, I should say that he was applying scientific induction.
	(I could of course also describe his behaviour in many other ways.)
	The works and customs of mankind do not seem to be very suitable material to which to apply scientific induction.
	A very large part of space-time must be investigated, if reliable results are to be obtained.
	Otherwise we may (as most English children do) decide that everybody speaks English, and that it is silly to learn French.
</p>
<p>
	There are, however, special remarks to be made about many of the disabilities that have been mentioned.
	The inability to enjoy strawberries and cream may have struck the reader as frivolous.
	Possibly a machine might be made to enjoy this delicious dish, but any attempt to make one do so would be idiotic.
	What is important about this disability is that it con&#173;tributes to some of the other disabilities, <abbr title="for example"><i lang="la" xml:lang="la">e.g.</i></abbr> to the difficulty of the same kind of friendliness occurring between man and machine as between white man and white man, or between black man and black man.
</p>
<p>
	The claim that “machines cannot make mistakes” seems a curious one.
	One is tempted to retort, “Are they any the worse for that?”
	But let us adopt a more sympathetic attitude, and try to see what is really meant.
	I think this criticism can be explained in terms of the imitation game.
	It is claimed that the interrogator could distinguish the machine from the man simply by setting them a number of problems in arithmetic.
	The machine would be unmasked because of its deadly accuracy.
	The reply to this is simple.
	The machine (programmed for playing the game) would not attempt to give the right answers to the arithmetic problems.
	It would deliberately introduce mistakes in a manner calculated to confuse the interrogator.
	A mechanical fault would probably show itself through an unsuit&#173;able decision as to what sort of a mistake to make in the arithmetic.
	Even this interpretation of the criticism is not sufficiently sympathetic.
	But we cannot afford the space to go into it much further.
	It seems to me that this criticism depends<span epub:type="pagebreak" id="page-449" title="449"></span> on a confusion between two kinds of mistake.
	We may call them ‘errors of functioning’ and ‘errors of conclusion’.
	Errors of functioning are due to some mechanical or electrical fault which causes the machine to behave otherwise than it was designed to do.
	In philosophical discussions one likes to ignore the possibility of such errors; one is therefore discussing ‘abstract machines’.
	These abstract machines are mathematical fictions rather than physical objects.
	By definition they are incapable of errors of functioning.
	In this sense we can truly say that “machines can never make mistakes”.
	Errors of con&#173;clusion can only arise when some meaning is attached to the output signals from the machine.
	The machine might, for instance, type out mathematical equations, or sentences in English.
	When a false proposition is typed we say that the machine has committed an error of conclusion.
	There is clearly no reason at all for saying that a machine cannot make this kind of mistake.
	It might do nothing but type out repeatedly “0 = 1”.
	To take a less perverse example, it might have some method for drawing conclusions by scientific induction.
	We must expect such a method to lead occasionally to erroneous results.
</p>
<p>
	The claim that a machine cannot be the subject of its own thought can of course only be answered if it can be shown that the machine has <em>some</em> thought with <em>some</em> subject matter.
	Never&#173;theless, ‘the subject matter of a machine’s operations’ does seem to mean something, at least to the people who deal with it.
	If, for instance, the machine was trying to find a solution of the equation <var>x</var><sup>2</sup> − 40&#8290;<var>x</var> − 11 = 0 one would be tempted to de&#173;scribe this equation as part of the machine’s subject matter at that moment.
	In this sort of sense a machine undoubtedly can be its own subject matter.
	It may be used to help in making up its own programmes, or to predict the effect of alterations in its own structure.
	By observing the results of its own behaviour it can modify its own programmes so as to achieve some purpose more effectively.
	These are possibilities of the near future, rather than Utopian dreams.
</p>
<p>
	The criticism that a machine cannot have much diversity of behaviour is just a way of saying that it cannot have much storage capacity.
	Until fairly recently a storage capacity of even a thousand digits was very rare.
</p>
<p>
	The criticisms that we are considering here are often disguised forms of the argument from consciousness.
	Usually if one main&#173;tains that a machine can do one of these things, and describes the kind of method that the machine could use, one will not make<span epub:type="pagebreak" id="page-450" title="450"></span> much of an impression.
	It is thought that the method (whatever it may be, for it must be mechanical) is really rather base.
	Compare the parentheses in Jefferson’s statement quoted on <abbr title="page">p.</abbr> 21.
</p>
</section>
<section id="subsection-6-6" epub:type="subchapter">
<h1 id="lady-lovelaces-objection">Lady Lovelace’s Objection</h1>
<p>
	Our most detailed information of Babbage’s Analytical Engine comes from a memoir by <cite>Lady Lovelace</cite>.
	In it she states, <q>The Analytical Engine has no pre&#173;tensions to <em>originate</em> anything.
	It can do <em>whatever we know how to order it</em> to perform</q> (her italics).
	This statement is quoted by <cite>Hartree</cite> (<abbr title="page">p.</abbr> 70) who adds:
	<q>This does not imply that it may not be possible to construct electronic equipment which will ‘think for itself’, or in which, in biological terms, one could set up a conditioned reflex, which would serve as a basis for ‘learning’.
	Whether this is possible in principle or not is a stimulating and exciting question, suggested by some of these recent developments.
	But it did not seem that the machines constructed or projected at the time had this property.</q>
</p>
<p>
	I am in thorough agreement with Hartree over this.
	It will be noticed that he does not assert that the machines in question had not got the property, but rather that the evidence available to Lady Lovelace did not encourage her to believe that they had it.
	It is quite possible that the machines in question had in a sense got this property.
	For suppose that some discrete-state machine has the property.
	The Analytical Engine was a universal digital computer, so that, if its storage capacity and speed were adequate, it could by suitable programming be made to mimic the machine in question.
	Probably this argument did not occur to the Countess or to Babbage.
	In any case there was no obligation on them to claim all that could be claimed.
</p>
<p>
	This whole question will be considered again under the heading of learning machines.
</p>
<p>
	A variant of Lady Lovelace’s objection states that a machine can “never do anything really new”.
	This may be parried for a moment with the saw, “There is nothing new under the sun”.
	Who can be certain that “original work” that he has done was not simply the growth of the seed planted in him by teaching, or the effect of following well-known general principles.
	A better variant of the objection says that a machine can never “take us by surprise”.
	This statement is a more direct challenge and can be met directly.
	Machines take me by surprise with great frequency.
	This is largely because I do not do sufficient calculation to decide what to expect them to do, or rather because, although I do a calculation, I do it in a hurried, slipshod fashion, taking risks.
	Perhaps I say to myself, “I suppose the Voltage here ought to he the same as there: anyway let’s assume it is.”
	<span epub:type="pagebreak" id="page-451" title="451"></span>
	Naturally I am often wrong, and the result is a surprise for me for by the time the experiment is done these assumptions have been forgotten.
	These admissions lay me open to lectures on the subject of my vicious ways, but do not throw any doubt on my credibility when I testify to the surprises I experience.
</p>
<p>
	I do not expect this reply to silence my critic.
	He will pro&#173;bably say that h surprises are due to some creative mental act on my part, and reflect no credit on the machine.
	This leads us back to the argument from consciousness, and far from the idea of surprise.
	It is a line of argument we must consider closed, but it is perhaps worth remarking that the appreciation of some&#173;thing as surprising requires as much of a “creative mental act” whether the surprising event originates from a man, a book, a machine or anything else.
</p>
<p>
	The view that machines cannot give rise to surprises is due, I believe, to a fallacy to which philosophers and mathematicians are particularly subject.
	This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it.
	It is a very use&#173;ful assumption under many circumstances, but one too easily forgets that it is false.
	A natural consequence of doing so is that one then assumes that there is no virtue in the mere working out of consequences from data and general principles.
</p>
</section>
<section id="subsection-6-7" epub:type="subchapter">
<h1 id="argument-from-continuity-in-the-nervous-system">Argument from Continuity in the Nervous System</h1>
<p>
	The nervous system is certainly not a discrete-state machine.
	A small error in the information about the size of a nervous impulse impinging on a neuron, may make a large difference to the size of the outgoing impulse.
	It may be argued that, this being so, one cannot expect to be able to mimic the behaviour of the nervous system with a discrete-state system.
</p>
<p>
	It is true that a discrete-state machine must be different from a continuous machine.
	But if we adhere to the conditions of the imitation game, the interrogator will not be able to take any advantage of this difference.
	The situation can be made clearer if we consider sonic other simpler continuous machine.
	A differential analyser will do very well.
	(A differential analyser is a certain kind of machine not of the discrete-state type used for some kinds of calculation.)
	Some of these provide their answers in a typed form, and so are suitable for taking part in the game.
	It would not be possible for a digital computer to predict exactly what answers the differential analyser would give to a problem, but it would be quite capable of giving the right sort of answer.
	For instance, if asked to give the value of π (actually about 3.1416) it would be reasonable<span epub:type="pagebreak" id="page-452" title="452"></span> to choose at random between the values 3.12, 3.13, 3.14, 3.15, 3.16 with the probabilities of 0.05, 0.15, 0.55, 0.19, 0.06 (say).
	Under these circumstances it would be very difficult for the interrogator to distinguish the differential analyser from the digital computer.
</p>
</section>
<section id="subsection-6-8" epub:type="subchapter">
<h1 id="the-argument-from-informality-of-behaviour">The Argument from Informality of Behaviour</h1>
<p>
	It is not possible to produce a set of rules purporting to describe what a man should do in every conceivable set of circumstances.
	One might for instance have a rule that one is to stop when one sees a red traffic light, and to go if one sees a green one, but what if by some fault both appear together?
	One may perhaps decide that it is safest to stop.
	But some further difficulty may well arise from this decision later.
	To attempt to provide rules of conduct to cover every eventuality, even those arising from traffic lights, appears to be impossible.
	With all this I agree.
</p>
<p>
	From this it is argued that we cannot be machines.
	I shall try to reproduce the argument, but I fear I shall hardly do it justice.
	It seems to run something like this.
	“If each man had a definite set of rules of conduct by which he regulated his life he would be no better than a machine.
	But there are no such rules, so men cannot be machines.”
	The undistributed middle is glaring.
	I do not think the argument is ever put quite like this, but I believe this is the argument used nevertheless.
	There may however be a certain confusion between ‘rules of conduct’ and ‘laws of behaviour‘’ to cloud the issue.
	By ‘rules of conduct’ I mean precepts such as “Stop if you see red lights”, on which one can act, and of which one can be conscious.
	By ‘laws of behaviour’ I mean laws of nature as applied to a man’s body such as “if you pinch him he will squeak”.
	If we substitute “laws of behaviour which regulate his life” for “laws of conduct by which he regulates his life” in the argument quoted the un&#173;distributed middle is no longer insuperable.
	For we believe that it is not only true that being regulated by laws of behaviour implies being some sort of machine (though not necessarily a discrete-state machine), but that conversely being such a machine implies being regulated by such laws.
	However, we cannot so easily convince ourselves of the absence of complete laws of behaviour as of complete rules of conduct.
	The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, “We have searched enough.
	There are no such laws.”
</p>
<p>
	We can demonstrate more forcibly that any such statement would be unjustified.
	For suppose we could be sure of finding<span epub:type="pagebreak" id="page-453" title="453"></span> such laws if they existed.
	Then given a discrete-state machine it should certainly be possible to discover by observation sufficient about it to predict its future behaviour, and this within a reason&#173;able time, say a thousand years.
	But this does not seem to be the case.
	I have set up on the Manchester computer a small programme using only 1000 units of storage, whereby the machine supplied with one sixteen figure number replies with another within two seconds.
	I would defy anyone to learn from these replies sufficient about the programme to be able to predict any replies to untried values.
</p>
</section>
<section id="subsection-6-9" epub:type="subchapter">
<h1 id="the-argument-from-extrasensory-perception">The Argument from Extrasensory Perception</h1>
<p>
	I assume that the reader is familiar with the idea of extrasensory per&#173;ception, and the meaning of the four items of it, <abbr title="that is to say"><i lang="la" xml:lang="la">viz.</i></abbr>, telepathy, clairvoyance, precognition and psychokinesis.
	These disturb&#173;ing phenomena seem to deny all our usual scientific ideas.
	How we should like to discredit them!
	Unfortunately the statistical evidence, at least for telepathy, is overwhelming.
	It is very difficult to rearrange one’s ideas so as to fit these new facts in.
	Once one has accepted them it does not seem a very big step to believe in ghosts and bogies.
	The idea that our bodies move simply according to the known laws of physics, together with some others not yet discovered but somewhat similar, would be one of the first to go.
</p>
<p>
	This argument is to my mind quite a strong one.
	One can say in reply that many scientific theories seem to remain workable in practice, in spite of clashing with <abbr title="extrasensory perception">E.S.P.</abbr>; that in fact one can get along very nicely if one forgets about it.
	This is rather cold comfort, and one fears that thinking is just the kind of phenomenon where <abbr>E.S.P.</abbr> may be especially relevant.
</p>
<p>
	A more specific argument based on <abbr>E.S.P.</abbr> might run as follows: “Let us play the imitation game, using as witnesses a man who is good as a telepathic receiver, and a digital computer.
	The interrogator can ask such questions as ‘What suit does the card in my right hand belong to?’
	The man by telepathy or clair&#173;voyance gives the right answer 130 times out of 400 cards.
	The machine can only guess at random, and perhaps gets 104 right, so the interrogator makes the right identification.”
	There is an interesting possibility which opens here.
	Suppose the digital com&#173;puter contains a random number generator.
	Then it will be natural to use this to decide what answer to give.
	But then the random number generator will be subject to the psychokinetic powers of the interrogator.
	Perhaps this psychokinesis might cause the machine to guess right more often than would be expected on a probability calculation, so that the interrogator<span epub:type="pagebreak" id="page-454" title="454"></span> might still be unable to make the right identification.
	On the other hand, he might be able to guess right without any question&#173;ing, by clairvoyance.
	With <abbr>E.S.P.</abbr> anything may happen.
</p>
<p>
	If telepathy is admitted it will be necessary to tighten our test up.
	The situation could be regarded as analogous to that which would occur if the interrogator were talking to himself and one of the competitors was listening with his ear to the wall.
	To put the competitors into a ‘telepathy-proof room’ would satisfy all requirements.
</p>
</section>
</section>
</body>
</html>
